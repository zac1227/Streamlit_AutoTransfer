import streamlit as st
import pandas as pd
import base64
import os
import io

from test import generate_codebook  # ç¢ºä¿ test.py æœ‰æ”¾å°ä½ç½®ä¸¦å«æœ‰è©²å‡½å¼
st.set_page_config(page_title="Codebook ç”¢ç”Ÿå™¨", layout="wide")
# âœ… ğŸš¨ è«‹ç¢ºä¿é€™æ®µæ”¾åœ¨æ‰€æœ‰ tab1/tab2 ä¹‹å‰ï¼
def read_uploaded_csv(uploaded_file):
    for enc in ["utf-8", "utf-8-sig", "cp950", "big5"]:
        try:
            return pd.read_csv(io.TextIOWrapper(uploaded_file, encoding=enc))
        except Exception:
            uploaded_file.seek(0)
            continue
    st.error("âŒ æª”æ¡ˆç„¡æ³•è®€å–ï¼Œè«‹ç¢ºèªæ˜¯å¦ç‚ºæœ‰æ•ˆçš„ CSV ä¸¦ä½¿ç”¨å¸¸è¦‹ç·¨ç¢¼ï¼ˆUTF-8ã€BIG5ã€CP950ï¼‰")
    return None
tab1, tab2 = st.tabs(["ğŸ“„ Codebook ç”¢ç”Ÿå™¨","ğŸ“Š é€²éšåˆ†æå·¥å…·", ])


with tab1:
    st.title("ğŸ“„ è‡ªå‹•åŒ– Codebook ç”¢ç”Ÿå·¥å…·")

    st.markdown("""### ğŸ“˜ åŠŸèƒ½èªªæ˜
    æœ¬å·¥å…·å¯æ ¹æ“š `code.csv` ä¸­çš„ Type æ¬„ä½ï¼Œå°ä¸»è³‡æ–™é€²è¡Œä»¥ä¸‹è½‰æ›ï¼š

    - `0`ï¼šç•¥é
    - `1`ï¼šæ•¸å€¼å‹
    - `2`ï¼šé¡åˆ¥å‹
    - `y1` æˆ– `y2`ï¼šç›®æ¨™è®Šæ•¸ï¼Œåˆ†åˆ¥ä»£è¡¨æ•¸å€¼å‹èˆ‡é¡åˆ¥å‹
    """)

    # ğŸ”¹ ä¸Šå‚³å€
    uploaded_maindata = st.file_uploader("ğŸ“‚ ä¸»è³‡æ–™æª”ï¼ˆCSVï¼‰", type=["csv"])
    uploaded_codebook = st.file_uploader("ğŸ“‹ è®Šæ•¸å®šç¾©æª” code.csvï¼ˆéœ€å« Column èˆ‡ Typeï¼‰", type=["csv"])

    df = code_df = None
    if uploaded_maindata:
        df = read_uploaded_csv(uploaded_maindata)
        if df is not None:
            st.success(f"âœ… æˆåŠŸè®€å–ä¸»è³‡æ–™ï¼š{df.shape[0]} ç­†ã€{df.shape[1]} æ¬„")
            with st.expander("ğŸ” é è¦½ä¸»è³‡æ–™"):
                st.dataframe(df.head())

    if uploaded_codebook:
        code_df = read_uploaded_csv(uploaded_codebook)
        if code_df is not None:
            st.success(f"âœ… æˆåŠŸè®€å– code.csvï¼šå…± {len(code_df)} æ¬„ä½")

    # ğŸ”¹ éºå¤±å€¼çµ±è¨ˆ
    if df is not None:
        st.markdown("---")
        st.subheader("ğŸ“‰ éºå¤±å€¼çµ±è¨ˆ")
        na_counts = df.isnull().sum()
        na_percent = df.isnull().mean() * 100
        na_df = pd.DataFrame({
            "æ¬„ä½åç¨±": na_counts.index,
            "éºå¤±æ•¸": na_counts.values,
            "éºå¤±æ¯”ä¾‹ (%)": na_percent.round(2).values
        })
        na_df = na_df[na_df["éºå¤±æ•¸"] > 0].sort_values(by="éºå¤±æ•¸", ascending=False)
        if na_df.empty:
            st.info("âœ… ç„¡éºå¤±å€¼")
        else:
            st.warning("âš ï¸ ä»¥ä¸‹æ¬„ä½æœ‰éºå¤±å€¼ï¼š")
            st.dataframe(na_df)
            st.write(f"ğŸ“¦ è‹¥åˆªé™¤æ‰€æœ‰å«éºå¤±å€¼è³‡æ–™ï¼Œå‰©é¤˜ç­†æ•¸ç‚ºï¼š**{df.dropna().shape[0]} ç­†**")

    # ğŸ”¹ å ±å‘Šç”¢å‡ºå€
    st.markdown("---")
    

    if df is not None and code_df is not None:
        code_df = code_df[~code_df["Type"].astype(str).str.lower().eq("0")]

        column_types = {}
        variable_names = {}
        column_roles = {}
        x_counter = y_counter = 1

        for _, row in code_df.iterrows():
            col = row["Column"]
            t = str(row["Type"]).lower()
            if t == "y1":
                column_roles[col] = "Y"
                column_types[col] = 1
            elif t == "y2":
                column_roles[col] = "Y"
                column_types[col] = 2
            elif t in ["1", "2"]:
                column_roles[col] = f"X{x_counter}"
                column_types[col] = int(t)
                x_counter += 1
            else:
                st.warning(f"âš ï¸ Unknown Type '{t}' for column '{col}' â€” skipped.")
                continue
            variable_names[col] = column_roles.get(col, col)

        # ğŸ”¹ è®Šæ•¸é¡å‹çµ±è¨ˆ
        st.subheader("ğŸ“Š è®Šæ•¸é¡å‹çµ±è¨ˆ")
        type_count = pd.Series(column_types).value_counts().sort_index()
        type_label_map = {1: "æ•¸å€¼å‹ (Type 1)", 2: "é¡åˆ¥å‹ (Type 2)"}
        type_summary = pd.DataFrame({
            "è®Šæ•¸é¡å‹": [type_label_map.get(t, f"å…¶ä»– ({t})") for t in type_count.index],
            "æ¬„ä½æ•¸": type_count.values
        })
        st.dataframe(type_summary)
        st.markdown("---")
        st.subheader("ğŸ“¤ Codebook å ±å‘Šç”¢å‡º")
        category_definitions = {}  # å¯åŠ å…¥å°æ‡‰æ¨™ç±¤
        if st.button("ğŸš€ ç”¢å‡º Codebook å ±å‘Š"):
            with st.spinner("ğŸ“„ ç”¢å‡ºä¸­ï¼Œè«‹ç¨å€™..."):
                try:
                    output_path = "codebook.docx"
                    output_path = generate_codebook(
                        df, column_types, variable_names, category_definitions,
                        code_df=code_df, output_path=output_path
                    )
                    with open(output_path, "rb") as f:
                        b64 = base64.b64encode(f.read()).decode()
                        href = f'<a href="data:application/vnd.openxmlformats-officedocument.wordprocessingml.document;base64,{b64}" download="{output_path}">ğŸ“¥ é»æˆ‘ä¸‹è¼‰ Codebook å ±å‘Š</a>'
                        st.markdown(href, unsafe_allow_html=True)
                    st.success("âœ… å ±å‘Šç”¢å‡ºå®Œæˆï¼")
                except Exception as e:
                    st.error(f"âŒ å ±å‘Šç”¢å‡ºå¤±æ•—ï¼š{e}")


# ---------- Tab 2 ----------
with tab2:
    st.title("ğŸ“Š é€²éšåˆ†æå·¥å…·")

    st.markdown("""
    ### ğŸ“˜ åŠŸèƒ½èªªæ˜
    æœ¬å·¥å…·å¯æ ¹æ“š `code.csv` ä¸­çš„ Transform æ¬„ä½ï¼Œå°ä¸»è³‡æ–™é€²è¡Œä»¥ä¸‹è½‰æ›ï¼š

    - è‹¥ Transform æ¬„ç‚ºç©ºæˆ– 'none'ï¼Œå‰‡ä¸é€²è¡Œä»»ä½•è½‰æ›ã€‚
    - è‹¥ç‚º `cut:[0,100,200,300]`ï¼Œå°‡ä»¥æ‰‹å‹•åˆ†ç®±æ–¹å¼é€²è¡Œå€é–“åˆ†é¡ï¼ˆå«é‚Šç•Œï¼‰ï¼Œè‡ªå‹•è½‰ç‚º 0, 1, 2...ã€‚
    - å¦‚: `cut:[0,100,200,300]` æœƒå°‡æ•¸å€¼åˆ†ç‚º 0-99, 100-199, 200-300 ä¸‰å€‹å€é–“ã€‚
    - è‹¥ Transform æ¬„ç‚º `onehot`ï¼Œå‰‡æœƒé€²è¡Œ one-hot encodingï¼Œä¸¦è½‰ç‚º 0/1ã€‚
    

    æ‰€æœ‰è½‰æ›å¾Œçš„æ¬„ä½åç¨±å°‡è‡ªå‹•åŠ ä¸Š `_binned` æˆ–å°æ‡‰æ¬„ä½å‰ç¶´ï¼ŒåŸå§‹æ¬„ä½å°‡è¢«ç§»é™¤ã€‚
    è½‰æ›å¾Œå°‡ä¾æ“šåŸå§‹ code.csv æ›´æ–° Type è³‡è¨Šä¸¦è‡ªå‹•ç”¢å‡º Codebookã€‚
    """)

    def read_uploaded_csv(uploaded_file):
        for enc in ["utf-8", "utf-8-sig", "cp950", "big5"]:
            try:
                return pd.read_csv(io.TextIOWrapper(uploaded_file, encoding=enc))
            except Exception:
                uploaded_file.seek(0)
                continue
        st.error("âŒ æª”æ¡ˆç„¡æ³•è®€å–ï¼Œè«‹ç¢ºèªæ˜¯å¦ç‚ºæœ‰æ•ˆçš„ CSV ä¸¦ä½¿ç”¨å¸¸è¦‹ç·¨ç¢¼ï¼ˆUTF-8ã€BIG5ã€CP950ï¼‰")
        return None

    uploaded_main = st.file_uploader("ğŸ“‚ è«‹ä¸Šå‚³ä¸»è³‡æ–™ï¼ˆCSVï¼‰", type=["csv"], key="main2")
    uploaded_code = st.file_uploader("ğŸ“‹ è«‹ä¸Šå‚³ code.csvï¼ˆéœ€åŒ…å« Columnã€ Typeã€ Transformæ¬„ä½ï¼‰", type=["csv"], key="code2")

    df2, code2 = None, None

    if uploaded_main:
        df2 = read_uploaded_csv(uploaded_main)
    if uploaded_code:
        code2 = read_uploaded_csv(uploaded_code)

    if df2 is not None and code2 is not None:
        st.success("âœ… è³‡æ–™èˆ‡ code.csv è¼‰å…¥æˆåŠŸ")
        st.success(f"âœ…ä¸»è³‡æ–™å…± {df2.shape[0]} ç­†ï¼Œ{df2.shape[1]} æ¬„ä½ã€‚")
        code2 = code2[~code2["Type"].astype(str).str.lower().eq("0")]

        variable_names = {}
        column_types = {}
        category_definitions = {}

        for _, row in code2.iterrows():
            col = row["Column"]
            t = str(row["Type"]).lower()
            transform = str(row.get("Transform", "")).strip()

            if col not in df2.columns:
                continue

            if transform == '' or transform.lower() == 'none':
                column_types[col] = int(t[-1]) if t.startswith("y") else int(t)
                variable_names[col] = col
                continue

            if transform.lower().startswith("cut:["):
                try:
                    bins = eval(transform[4:])
                    new_col = col + "_binned"
                    df2[new_col] = pd.cut(df2[col], bins=bins, include_lowest=True, labels=False)
                    column_types[new_col] = 2
                    variable_names[new_col] = col
                    df2.drop(columns=[col], inplace=True)
                except Exception as e:
                    st.warning(f"ğŸ”¸ {col} åˆ†ç®±å¤±æ•—ï¼š{e}")
            
            elif df2[col].dtype == 'object' or transform.lower() == 'onehot':
                try:
                    onehot = pd.get_dummies(df2[col], prefix=col, dtype=int)
                    for new_col in onehot.columns:
                        column_types[new_col] = 2
                        variable_names[new_col] = new_col
                    df2 = pd.concat([df2.drop(columns=[col]), onehot], axis=1)
                except Exception as e:
                    st.warning(f"ğŸ”¸ {col} one-hot ç·¨ç¢¼å¤±æ•—ï¼š{e}")
            else:
                st.warning(f"ğŸ”¸ æœªçŸ¥ Transform æŒ‡ä»¤ï¼š{transform}ï¼ˆæ¬„ä½ {col}ï¼‰")

        st.markdown("---")
        st.subheader("ğŸ” é è¦½è½‰æ›å¾Œè³‡æ–™")
        st.dataframe(df2.head())
                # ğŸ” éºå¤±å€¼çµ±è¨ˆ
        st.subheader("ğŸ“‰ éºå¤±å€¼çµ±è¨ˆ")
        na_counts = df2.isnull().sum()
        na_percent = df2.isnull().mean() * 100
        na_df = pd.DataFrame({
            "æ¬„ä½åç¨±": na_counts.index,
            "éºå¤±æ•¸": na_counts.values,
            "éºå¤±æ¯”ä¾‹ (%)": na_percent.round(2).values
        })
        na_df = na_df[na_df["éºå¤±æ•¸"] > 0].sort_values(by="éºå¤±æ•¸", ascending=False)
        if na_df.empty:
            st.info("âœ… ç„¡éºå¤±å€¼")
        else:
            st.warning("âš ï¸ ä»¥ä¸‹æ¬„ä½æœ‰éºå¤±å€¼ï¼š")
            st.dataframe(na_df)
            rows_after_na = df2.dropna().shape[0]
            st.write(f"ğŸ“¦ åˆªé™¤æ‰€æœ‰å«éºå¤±å€¼çš„è³‡æ–™å¾Œï¼Œå‰©é¤˜ç­†æ•¸ç‚º {rows_after_na} ç­†è³‡æ–™")
        # ğŸ” è®Šæ•¸é¡å‹çµ±è¨ˆ
        st.markdown("---")
        st.subheader("ğŸ“Š è®Šæ•¸é¡å‹çµ±è¨ˆ")
        type_count = pd.Series(column_types).value_counts().sort_index()
        type_label_map = {
            1: "æ•¸å€¼å‹ (Type 1)",
            2: "é¡åˆ¥å‹ (Type 2)"
        }
        type_summary = pd.DataFrame({
            "è®Šæ•¸é¡å‹": [type_label_map.get(t, f"å…¶ä»– ({t})") for t in type_count.index],
            "æ¬„ä½æ•¸": type_count.values
        })
        st.dataframe(type_summary)
        csv = df2.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ğŸ“¥ ä¸‹è¼‰è½‰æ›å¾Œçš„ CSV", data=csv, file_name="transformed_data.csv", mime="text/csv")
        # âœ… è£½ä½œè½‰æ›å¾Œçš„ code_df
        code_df_transformed = pd.DataFrame({
            "Column": list(variable_names.keys()),
            "Type": [column_types[col] for col in variable_names.keys()]
        })

        # âœ… è¼¸å‡ºè½‰æ›å¾Œçš„ code.csv
        code_df_transformed.to_csv("code_transformed.csv", index=False, encoding="utf-8-sig")

        # âœ… åŠ å…¥ä¸‹è¼‰æŒ‰éˆ•
        csv_code = code_df_transformed.to_csv(index=False, encoding='utf-8-sig')
        st.download_button("ğŸ“¥ ä¸‹è¼‰è½‰æ›å¾Œçš„ code.csv", data=csv_code, file_name="code_transformed.csv", mime="text/csv")
        st.markdown("---")
        st.subheader("ğŸ“˜ è‡ªå‹•ç”¢å‡º Codebook")
        if st.button("ğŸ“„ ç”¢ç”Ÿå ±å‘Šï¼ˆè½‰æ›å¾Œè³‡æ–™ï¼‰"):
            with st.spinner("ç”¢å‡ºä¸­..."):
                try:
                    output_path = "transformed_codebook.docx"
                    code_df_transformed = pd.DataFrame({
                    "Column": list(column_types.keys()),
                    "Type": [column_types[k] for k in column_types],
                })
                    generate_codebook(df2, column_types, variable_names, category_definitions, code_df=code_df_transformed, output_path=output_path)
                    
                    with open(output_path, "rb") as f:
                        b64 = base64.b64encode(f.read()).decode()
                        href = f'<a href="data:application/vnd.openxmlformats-officedocument.wordprocessingml.document;base64,{b64}" download="{output_path}">ğŸ“¥ ä¸‹è¼‰ Codebook å ±å‘Šï¼ˆè½‰æ›å¾Œï¼‰</a>'
                        st.markdown(href, unsafe_allow_html=True)
                    st.success("âœ… Codebook å·²ç”¢å‡ºï¼")
                except Exception as e:
                    st.error(f"âŒ å ±å‘Šç”¢å‡ºå¤±æ•—ï¼š{e}")




