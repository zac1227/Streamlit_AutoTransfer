import streamlit as st
import pandas as pd
import base64
import os
import io

from test import generate_codebook  # ç¢ºä¿ test.py æœ‰æ”¾å°ä½ç½®ä¸¦å«æœ‰è©²å‡½å¼
st.set_page_config(page_title="Codebook ç”¢ç”Ÿå™¨", layout="wide")
tab1, tab2 = st.tabs(["ğŸ“„ Codebook ç”¢ç”Ÿå™¨","ğŸ“Š é€²éšåˆ†æå·¥å…·", ])


with tab1:
    st.title("ğŸ“„ è‡ªå‹•åŒ– Codebook ç”¢ç”Ÿå·¥å…·")
    # ---------- ğŸ“¥ ä¸Šå‚³å€å¡Š ----------
    
    

    def read_uploaded_csv(uploaded_file):
        for enc in ["utf-8", "utf-8-sig", "cp950", "big5"]:
            try:
                return pd.read_csv(io.TextIOWrapper(uploaded_file, encoding=enc))
            except Exception:
                uploaded_file.seek(0)
                continue
        st.error("âŒ æª”æ¡ˆç„¡æ³•è®€å–ï¼Œè«‹ç¢ºèªæ˜¯å¦ç‚ºæœ‰æ•ˆçš„ CSV ä¸¦ä½¿ç”¨å¸¸è¦‹ç·¨ç¢¼ï¼ˆUTF-8ã€BIG5ã€CP950ï¼‰")
        return None

    uploaded_maindata = st.file_uploader("ğŸ“‚ è«‹ä¸Šå‚³ä¸»è³‡æ–™æª”ï¼ˆCSVï¼‰", type=["csv"])
    uploaded_codebook = st.file_uploader("ğŸ“‹ è«‹ä¸Šå‚³è®Šæ•¸é¡å‹æª” code.csvï¼ˆéœ€åŒ…å« Column èˆ‡ Type æ¬„ä½ï¼‰", type=["csv"])

    df = None
    code_df = None

    if uploaded_maindata:
        df = read_uploaded_csv(uploaded_maindata)
        if df is not None:
            st.success(f"âœ… æˆåŠŸè®€å–ä¸»è³‡æ–™ï¼Œå…± {df.shape[0]} ç­†ï¼Œ{df.shape[1]} æ¬„ä½ã€‚")
            with st.expander("ğŸ” é è¦½ä¸»è³‡æ–™"):
                st.dataframe(df.head())

    if uploaded_codebook:
        code_df = read_uploaded_csv(uploaded_codebook)
        if code_df is not None:
            st.success(f"âœ… æˆåŠŸè®€å– Codebookï¼Œå…±å®šç¾© {len(code_df)} æ¬„ä½ã€‚")

    # ---------- ğŸ§  è³‡æ–™è™•ç† ----------
    st.markdown("---")
    st.subheader("ğŸ“¤ å ±å‘Šç”¢å‡ºå€")

    if df is not None and code_df is not None:
    # ç§»é™¤ Type ç‚º 0 çš„æ¬„ä½
        code_df = code_df[~code_df["Type"].astype(str).str.lower().eq("0")]

        # å»ºç«‹æ¬„ä½å‹åˆ¥èˆ‡è§’è‰²ï¼ˆX æˆ– Yï¼‰
        column_types = {}
        variable_names = {}
        column_roles = {}
        x_counter = 1
        y_counter = 1

        for _, row in code_df.iterrows():
            col = row["Column"]
            t = str(row["Type"]).lower()

            if t == "y1":
                column_roles[col] = "Y"
                column_types[col] = 1
            elif t == "y2":
                column_roles[col] = "Y"
                column_types[col] = 2
            elif t in ["1", "2"]:
                column_roles[col] = f"X{x_counter}"
                column_types[col] = int(t)
                x_counter += 1
            else:
                st.warning(f"âš ï¸ Unknown Type '{t}' for column '{col}' â€” skipped.")
                continue

            variable_names[col] = column_roles.get(col, col)

                
        category_definitions = {}  # è‹¥ä½ ä¹‹å¾Œæƒ³åŠ å°æ‡‰å®šç¾©ï¼Œå¯æ”¾é€™è£¡
        if st.button("ğŸš€ ç”¢å‡º Codebook å ±å‘Š"):
            with st.spinner("ğŸ“„ ç”¢å‡ºä¸­ï¼Œè«‹ç¨å€™..."):
                try:
                    output_path = "codebook.docx"  # æ˜ç¢ºæŒ‡å®š Word æª”æ¡ˆåç¨±
                    output_path = generate_codebook(
                        df, column_types, variable_names, category_definitions,code_df=code_df ,output_path=output_path
                    )
                    with open(output_path, "rb") as f:
                        file_data = f.read()
                        b64 = base64.b64encode(file_data).decode()
                        href = f'<a href="data:application/vnd.openxmlformats-officedocument.wordprocessingml.document;base64,{b64}" download="{os.path.basename(output_path)}">ğŸ“¥ é»æˆ‘ä¸‹è¼‰ Codebook å ±å‘Šï¼ˆWordï¼‰</a>'
                        st.markdown(href, unsafe_allow_html=True)
                    st.success("âœ… å ±å‘Šå·²ç”¢å‡ºï¼Œå¯ç›´æ¥ä¸‹è¼‰ã€‚")
                except Exception as e:
                    st.error(f"âŒ ç”¢å‡ºå¤±æ•—ï¼š{e}")

# ---------- Tab 1 ----------
# ---------- Tab 2 ----------
with tab2:
    st.title("ğŸ“Š é€²éšåˆ†æå·¥å…·")
    st.markdown("""
    ### ğŸ“˜ åŠŸèƒ½èªªæ˜
    æœ¬å·¥å…·å¯æ ¹æ“š `code.csv` ä¸­çš„ Transform æ¬„ä½ï¼Œå°ä¸»è³‡æ–™é€²è¡Œä»¥ä¸‹è½‰æ›ï¼š

    - è‹¥ Transform æ¬„ç‚ºç©ºæˆ– 'none'ï¼Œå‰‡ä¸é€²è¡Œä»»ä½•è½‰æ›ã€‚
    - è‹¥ç‚º `cut:[0,10,20,30]`ï¼Œå°‡ä»¥æ‰‹å‹•åˆ†ç®±æ–¹å¼é€²è¡Œå€é–“åˆ†é¡ï¼ˆå«é‚Šç•Œï¼‰ã€‚
    - è‹¥ç‚º `cut:quantile:4`ï¼Œå‰‡æœƒé€²è¡Œå››ç­‰åˆ†çš„åˆ†ä½æ•¸åˆ‡åˆ†ã€‚
    - è‹¥ç‚º `cut:uniform:3`ï¼Œå‰‡æœƒå°‡è³‡æ–™ç­‰å¯¬åˆ‡ç‚ºä¸‰æ®µã€‚
    - è‹¥æ¬„ä½ç‚ºé¡åˆ¥å‹æ…‹ï¼Œæˆ– Transform æ¬„ç‚º `onehot`ï¼Œå‰‡æœƒé€²è¡Œ one-hot encodingã€‚

    æ‰€æœ‰è½‰æ›å¾Œçš„æ¬„ä½åç¨±å°‡è‡ªå‹•åŠ ä¸Š `_binned` æˆ–å°æ‡‰æ¬„ä½å‰ç¶´ã€‚
    """)
    def read_uploaded_csv(uploaded_file):
        for enc in ["utf-8", "utf-8-sig", "cp950", "big5"]:
            try:
                return pd.read_csv(io.TextIOWrapper(uploaded_file, encoding=enc))
            except Exception:
                uploaded_file.seek(0)
                continue
        st.error("âŒ æª”æ¡ˆç„¡æ³•è®€å–ï¼Œè«‹ç¢ºèªæ˜¯å¦ç‚ºæœ‰æ•ˆçš„ CSV ä¸¦ä½¿ç”¨å¸¸è¦‹ç·¨ç¢¼ï¼ˆUTF-8ã€BIG5ã€CP950ï¼‰")
        return None

    uploaded_main = st.file_uploader("ğŸ“‚ è«‹ä¸Šå‚³ä¸»è³‡æ–™ï¼ˆCSVï¼‰", type=["csv"], key="main2")
    uploaded_code = st.file_uploader("ğŸ“‹ è«‹ä¸Šå‚³ code.csvï¼ˆå« Transform æ¬„ä½ï¼‰", type=["csv"], key="code2")

    df2, code2 = None, None

    if uploaded_main:
        df2 = read_uploaded_csv(uploaded_main)
    if uploaded_code:
        code2 = read_uploaded_csv(uploaded_code)

    if df2 is not None and code2 is not None:
        st.success("âœ… è³‡æ–™èˆ‡ code.csv è¼‰å…¥æˆåŠŸ")
        transform_col = []
        for _, row in code2.iterrows():
            col = row["Column"]
            transform = str(row.get("Transform", "")).strip()
            if transform.lower().startswith("cut:["):
                try:
                    bins = eval(transform[4:])
                    df2[col + "_binned"] = pd.cut(df2[col], bins=bins, include_lowest=True)
                except Exception as e:
                    st.warning(f"ğŸ”¸ {col} åˆ†ç®±å¤±æ•—ï¼š{e}")
            elif transform.lower().startswith("cut:quantile:"):
                try:
                    q = int(transform.split(":")[-1])
                    df2[col + "_binned"] = pd.qcut(df2[col], q=q, duplicates='drop')
                except Exception as e:
                    st.warning(f"ğŸ”¸ {col} åˆ†ä½æ•¸åˆ‡åˆ†å¤±æ•—ï¼š{e}")
            elif transform.lower().startswith("cut:uniform:"):
                try:
                    k = int(transform.split(":")[-1])
                    df2[col + "_binned"] = pd.cut(df2[col], bins=k)
                except Exception as e:
                    st.warning(f"ğŸ”¸ {col} å‡åˆ†åˆ‡åˆ†å¤±æ•—ï¼š{e}")
            elif df2[col].dtype == 'object' or transform.lower() == 'onehot':
                try:
                    onehot = pd.get_dummies(df2[col], prefix=col)
                    df2 = pd.concat([df2, onehot], axis=1)
                except Exception as e:
                    st.warning(f"ğŸ”¸ {col} one-hot ç·¨ç¢¼å¤±æ•—ï¼š{e}")
            elif transform == '' or transform.lower() == 'none':
                continue
            else:
                st.warning(f"ğŸ”¸ æœªçŸ¥ Transform æŒ‡ä»¤ï¼š{transform}ï¼ˆæ¬„ä½ {col}ï¼‰")

        st.markdown("---")
        st.subheader("ğŸ” é è¦½è½‰æ›å¾Œè³‡æ–™")
        st.dataframe(df2.head())

        csv = df2.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ğŸ“¥ ä¸‹è¼‰è½‰æ›å¾Œçš„ CSV", data=csv, file_name="transformed_data.csv", mime="text/csv")
