from docx import Document
from docx.shared import Inches
import tempfile
import os

def generate_codebook(df, column_types, output_path="codebook.docx"):
    doc = Document()
    doc.add_heading("Codebook çµ±è¨ˆæ‘˜è¦å ±å‘Š", level=1)

    # ðŸŸ¦ é¦–é æ‘˜è¦çµ±è¨ˆ
    try:
        total_rows, total_cols = df.shape
        doc.add_paragraph(f"ç¸½ç­†æ•¸ï¼š{total_rows}")
        doc.add_paragraph(f"æ¬„ä½æ•¸ï¼š{total_cols}")
        doc.add_paragraph("å«ç¼ºå¤±å€¼æ¬„ä½ï¼š")

        na_series = df.isnull().sum()
        na_table = doc.add_table(rows=1, cols=3)
        na_table.style = "Table Grid"
        na_table.cell(0, 0).text = "æ¬„ä½åç¨±"
        na_table.cell(0, 1).text = "ç¼ºå¤±æ•¸"
        na_table.cell(0, 2).text = "ç¼ºå¤±æ¯”ä¾‹"

        for col in df.columns:
            na_count = na_series[col]
            if na_count > 0:
                row = na_table.add_row().cells
                row[0].text = col
                row[1].text = str(na_count)
                row[2].text = f"{na_count / total_rows:.2%}"
    except Exception as e:
        doc.add_paragraph(f"âš ï¸ æ‘˜è¦çµ±è¨ˆéŒ¯èª¤ï¼š{e}")

    # ðŸŸ¦ æ¯å€‹è®Šæ•¸æ‘˜è¦
    for col in df.columns:
        if col not in column_types:
            continue

        vartype = column_types[col]
        if vartype == "0" or vartype == "ç•¥éŽ":
            continue

        doc.add_heading(f"è®Šæ•¸ï¼š{col}", level=2)

        if vartype == "1" or vartype == "é€£çºŒ":
            clean_series = df[col].dropna()

            if not pd.api.types.is_numeric_dtype(clean_series):
                doc.add_paragraph("âš ï¸ è³‡æ–™éžæ•¸å€¼åž‹ï¼Œç•¥éŽ")
                continue

            mean_val = clean_series.mean()
            std_val = clean_series.std()
            min_val = clean_series.min()
            max_val = clean_series.max()

            table = doc.add_table(rows=3, cols=4)
            table.style = "Table Grid"
            table.cell(0, 0).text = "å¹³å‡æ•¸"
            
            #table.cell(0, 1).text = f"{mean_val:.3f}" if pd.notna(mean_val) else ""
            table.cell(0, 2).text = "æ¨™æº–å·®"
            table.cell(0, 3).text = f"{std_val:.3f}" if pd.notna(std_val) else ""
            table.cell(1, 0).text = "æœ€å¤§å€¼"
            table.cell(1, 1).text = f"{max_val:.3f}" if pd.notna(max_val) else ""
            table.cell(1, 2).text = "æœ€å°å€¼"
            table.cell(1, 3).text = f"{min_val:.3f}" if pd.notna(min_val) else ""

            # Histogram
            if len(clean_series) > 0:
                fig, ax = plt.subplots()
                clean_series.plot(kind="hist", bins=10, color="skyblue", edgecolor="black", ax=ax)
                ax.set_title(f"Histogram of {col}")
                tmp1 = tempfile.NamedTemporaryFile(delete=False, suffix=".png")
                plt.tight_layout()
                plt.savefig(tmp1.name)
                plt.close("all")
                doc.add_picture(tmp1.name, width=Inches(4.5))
                os.unlink(tmp1.name)

        elif vartype == "2" or vartype == "é¡žåˆ¥":
            value_counts = df[col].value_counts(dropna=False)
            total = len(df)

            table = doc.add_table(rows=1 + len(value_counts), cols=3)
            table.style = "Table Grid"
            table.cell(0, 0).text = "é¡žåˆ¥"
            table.cell(0, 1).text = "æ•¸é‡"
            table.cell(0, 2).text = "æ¯”ä¾‹"

            for i, (cat, count) in enumerate(value_counts.items(), start=1):
                table.cell(i, 0).text = str(cat)
                table.cell(i, 1).text = str(count)
                table.cell(i, 2).text = f"{count / total:.2%}"

            if len(value_counts) > 0:
                fig, ax = plt.subplots()
                value_counts.plot(kind="bar", color="cornflowerblue", ax=ax)
                ax.set_title(f"Bar Chart of {col}")
                tmp2 = tempfile.NamedTemporaryFile(delete=False, suffix=".png")
                plt.tight_layout()
                plt.savefig(tmp2.name)
                plt.close("all")
